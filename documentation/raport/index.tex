\documentclass{article}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{float} % For precise float placement
\usepackage{placeins} % For FloatBarrier
\usepackage{adjustbox} % For adjusting box sizes
\usepackage{pdfpages}
\usepackage{parskip}
\usepackage{indentfirst}

\setlength{\parindent}{2em} % Add this line to set paragraph indentation

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{2cm} % Adjust the vertical space as needed
    {\Huge \bfseries Application for Transcribing Grand Piano Recordings to Sheet Music in PDF\par}
    \vspace{8cm}
    {\Large \textbf{Subject:} Computer Engineering Project\par}
    \vspace{0.5cm}
    {\Large \textbf{Supervisor:} Prof. Mariagrazia Fugini\par}
    \vspace{0.5cm}
    {\Large \textbf{Author:} Micha≈Ç Jagoda\par}
    \vspace{0.5cm}
    {\Large \today\par}
    \vfill
\end{titlepage}

\clearpage % Start a new page before the ToC
\tableofcontents
\clearpage % Start a new page after the ToC

\section{Motivation of the Project}

The motivation behind this project includes:
\begin{itemize}
    \item \textbf{Problem-Solving:} Addressing the challenge of accurately transcribing complex piano music.
    \item \textbf{Innovation:} Leveraging AI to create new tools for musicians and educators.
    \item \textbf{Accessibility:} Making high-quality music transcription more accessible and convenient.
    \item \textbf{Personal Interest:} A passion for music and technology, and the desire to combine these fields in a meaningful way.
\end{itemize}


\section{Topic Analysis}

\subsection{Overview}
This project involves creating a desktop application designed to transcribe grand piano recordings into sheet music and export the results as a PDF. This involves the use of audio processing, music transcription, and PDF generation technologies, all performed locally without the need for an internet connection.

\subsection{Objectives}
\begin{itemize}
    \item To accurately transcribe piano recordings into readable sheet music.
    \item To provide a user-friendly interface for uploading audio files and exporting sheet music.
    \item To offer an offline and local application for accessibility and privacy reasons.
\end{itemize}

\subsection{Key Components}
\begin{itemize}
    \item \textbf{Audio Processing:} Capturing and processing the audio signals from the grand piano recordings using the \texttt{audio\_processor.py}.
    \item \textbf{AI Model:} Generating an initial transcription output from the uploaded MP3 file using the \texttt{transcription\_worker.py}.
    \item \textbf{Postprocessing Algorithm:} Creating a MIDI file from the AI model's output using the \texttt{Sheet\_music\_generation.py}.
    \item \textbf{PDF Generation:} Using the MuseScore API to generate a PDF from the generated MIDI file with \texttt{generate\_pdf.py}.
    \item \textbf{User Interface:} Allowing users to interact with the application, upload audio files, view PDF previews, listen to MIDI and MP3 files, and download the resulting sheet music and MIDI files via \texttt{window.py}.
\end{itemize}

\FloatBarrier % Ensures that all floats are processed before moving to the next section

\section{Technologies Used}
\begin{itemize}
    \item \textbf{Python:} The primary programming language used for developing the application.
    \item \textbf{Librosa:} A Python library for audio and music analysis, used for audio processing and feature extraction in \texttt{audio\_processor.py}.
    \item \textbf{Piano Transcription Inference:} A library for transcribing piano music, used in \texttt{transcription\_worker.py}.
    \item \textbf{Music21:} A toolkit for computer-aided musicology, used in \texttt{Sheet\_music\_generation.py} to create and manipulate music streams.
    \item \textbf{MuseScore:} A software for creating, playing, and printing sheet music, used in \texttt{generate\_pdf.py} to convert MIDI files to PDF.
    \item \textbf{PySide6:} A set of Python bindings for Qt libraries, used for creating the graphical user interface in \texttt{window.py}.
    \item \textbf{VLC:} A media player used for playing audio and MIDI files within the application.
    \item \textbf{Pdf2image:} A library for converting PDF files to images, used in the GUI to display PDF previews.
    \item \textbf{Tempfile:} A Python module used for creating temporary files, ensuring that the application handles file operations efficiently and securely.
    \item \textbf{WSL2 (Windows Subsystem for Linux):} Used to run some Python libraries that were not available on Windows. As WSL2 lacks support for audio and GUI components, server bridges were implemented to facilitate communication between the audio processing and GUI components running in different environments.
\end{itemize}

\FloatBarrier

\section{Functional Requirements}

\subsection{Core Functionalities}
\begin{itemize}
    \item \textbf{Audio File Upload:}
    \begin{itemize}
        \item Users can upload MP3 audio files.
    \end{itemize}
    \item \textbf{AI Model:}
    \begin{itemize}
        \item The system processes the uploaded audio using an AI model to generate an initial transcription.
    \end{itemize}
    \item \textbf{Postprocessing Algorithm:}
    \begin{itemize}
        \item The application converts the AI model's output into a MIDI file.
    \end{itemize}
    \item \textbf{PDF Generation:}
    \begin{itemize}
        \item The MuseScore API is used to convert the generated MIDI file into a PDF document.
    \end{itemize}
    \item \textbf{PDF Preview and Download:}
    \begin{itemize}
        \item Users can preview the PDF of the sheet music.
        \item Users can download the PDF and the MIDI file.
    \end{itemize}
    \item \textbf{Playback Feature:}
    \begin{itemize}
        \item Users can listen to the transcription by playing the MIDI file.
        \item Users can also listen to the original MP3 file.
    \end{itemize}
\end{itemize}

\FloatBarrier
\clearpage
\section{Non-Functional Requirements}

\subsection{Performance Requirements}
\begin{itemize}
    \item \textbf{Speed:} The transcription process should be completed within a reasonable time frame (under 15 minutes for a 5-minute recording).
    \item \textbf{Accuracy:} The transcription should accurately reflect the notes, rhythms, and dynamics of the original recording with a high degree of precision (over 90\% accuracy).
\end{itemize}

\subsection{Usability Requirements}
\begin{itemize}
    \item \textbf{User Interface:} The interface should be intuitive and easy to navigate, even for users with limited technical skills.
\end{itemize}

\subsection{Compatibility Requirements}
\begin{itemize}
    \item \textbf{File Format Support:} The application should support common audio file formats and produce PDFs that are compatible with standard PDF readers.
\end{itemize}

\subsection{Maintainability Requirements}
\begin{itemize}
    \item \textbf{Modularity:} The application code should be modular to facilitate easy updates and maintenance.
    \item \textbf{Documentation:} Comprehensive documentation should be provided for developers to understand the codebase and contribute to its development.
\end{itemize}

\subsection{Scalability Requirements}
\begin{itemize}
    \item \textbf{Future Expansion:} The architecture should allow for easy addition of new features and functionalities.
\end{itemize}

\FloatBarrier
\clearpage
\section{Use Case Diagram}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/use_case.png}
    \caption{Use Case Diagram}
    \label{fig:use_case}
\end{figure}

\FloatBarrier
\clearpage
\section{System Architecture Flow Chart}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/system_architecture.png}
    \caption{System Architecture Flow Chart}
    \label{fig:system_architecture}
\end{figure}

\FloatBarrier
\clearpage

\section{Class Diagram}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/class_diagram.png}
    \caption{Class Diagram}
    \label{fig:class_diagram}
\end{figure}

\FloatBarrier
\clearpage

\section{Sequence Diagrams}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/transcription_seq.png}
    \caption{Transcription process sequence diagram}
    \label{fig:transcription_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/audio_seq.png}
    \caption{Audio sequence diagram}
    \label{fig:audio_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/load_audio_seq.png}
    \caption{Load file sequence diagram}
    \label{fig:load_audio_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/save_midi_seq.png}
    \caption{Save MIDI sequence diagram}
    \label{fig:save_midi_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/save_pdf_seq.png}
    \caption{Save PDF sequence diagram}
    \label{fig:save_pdf_sequence_diagram}
\end{figure}

\FloatBarrier
\clearpage

\section{AI Model}
The AI model implemented for this project is based on the architecture proposed by Kong et al. in "High-resolution Piano Transcription with Pedals by Regressing Precise Onsets and Offsets Times." This model is designed to achieve high accuracy in transcribing both notes and pedal actions from piano recordings.

\subsection{Main Points of the AI Architecture}
\begin{itemize}
    \item \textbf{Input Features:} The input to the model is a log mel spectrogram of the audio recording, which provides a time-frequency representation of the sound.
    \item \textbf{Convolutional Layers:} These layers extract high-level features from the log mel spectrogram, capturing the essential information required for accurate transcription.
    \item \textbf{Bidirectional Gated Recurrent Units (biGRUs):} These layers model the temporal dependencies in the music, which are crucial for identifying the precise timing of notes and pedals.
    \item \textbf{Regression and Classification Outputs:} The model predicts continuous onset and offset times, velocities for notes, and the presence of notes and pedals in each frame.
\end{itemize}

\subsection{AI Model Architecture}
See Figure \ref{fig:ai_model_architecture} for the architecture of the AI model.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/ai_architecture.png}
    \caption{AI Model Architecture}
    \label{fig:ai_model_architecture}
\end{figure}

\subsection{Training Model}

The training process for the AI model involves several key steps to ensure high accuracy and robustness:

\begin{itemize}
    \item \textbf{Dataset:} The model was trained using the MAESTRO dataset, which contains high-quality piano recordings and corresponding MIDI files. This dataset is ideal due to its precision in time alignment.
    \item \textbf{Preprocessing:} Audio recordings were converted to mono and resampled to 16 kHz. Log mel spectrograms were then extracted with a Hanning window and mel filter banks.
    \item \textbf{Model Architecture:} The architecture includes convolutional blocks followed by biGRU layers. The convolutional layers help in extracting spatial features, while the biGRUs capture the temporal aspects of the music.
    \item \textbf{Loss Functions:} Multiple loss functions were used to train the model, including binary cross-entropy for frame-wise classification and regression losses for onset and offset predictions.
    \item \textbf{Training Procedure:} The model was trained using the Adam optimizer with a learning rate schedule. Dropout was used to prevent overfitting, and the model was trained for a large number of iterations to ensure convergence.
    \item \textbf{Hardware:} Training was performed on Google Cloud Platform using NVIDIA Tesla V100 GPUs to accelerate the process, and to make it possible to train the model in a reasonable time frame.
\end{itemize}

\subsection{Accuracy of AI}

The model achieved high accuracy in transcribing piano recordings:
\begin{itemize}
    \item \textbf{Onset F1 Score:} 96.72\% on the MAESTRO dataset, outperforming previous state-of-the-art models.
    \item \textbf{Pedal Onset F1 Score:} 91.86\%, marking the first benchmark result for pedal transcription on this dataset.
    \item \textbf{Robustness:} The model is robust to misalignments in the onset and offset labels, ensuring reliable performance even with noisy data.
\end{itemize}




\section{Implementation and Usage}

For the implementation and usage of the application, I encourage you to visit the GitHub repository: \href{https://github.com/mj300405/MP3_to_notes}{link to the repository}. The repository contains:
\begin{itemize}
    \item \textbf{README File:} Detailed instructions on how to set up and run the application.
    \item \textbf{Source Code:} All the necessary code files for the application, including:
    \begin{itemize}
        \item \textbf{audio\_processor.py:} Handles the preprocessing of audio recordings.
        \item \textbf{transcription\_worker.py:} Uses the AI model to generate initial transcriptions.
        \item \textbf{Sheet\_music\_generation.py:} Post-processes the AI model's output to create MIDI files.
        \item \textbf{generate\_pdf.py:} Converts MIDI files into sheet music PDFs using the MuseScore API.
        \item \textbf{window.py:} Provides the user interface for the application.
        \item \textbf{requirements.txt:} Lists all the required Python libraries and their versions.
        \item \textbf{AI Model:} Files related to model implementation, data preparation, training, evaluation, postprocessing, and inference.
    \end{itemize}
    \item \textbf{Commented Code:} The code is well-commented to facilitate understanding and further development.
    \item \textbf{Sample Audio Files:} Included in the repository for testing the application (folder samples).
\end{itemize}



\clearpage
\FloatBarrier
\section{Motivations of Pieces Chosen}

The pieces chosen for transcription were selected based on several factors:
\begin{itemize}
    \item \textbf{Complexity:} Pieces like Chopin's Etudes and Beethoven's Sonatas offer a wide range of technical challenges, making them ideal for testing the transcription capabilities of the AI model.
    \item \textbf{Popularity:} These pieces are well-known and frequently studied, providing a good benchmark for comparison.
    \item \textbf{Variety:} Including different styles and periods helps ensure the model is versatile and robust, allowing it to handle various musical textures and structures.
    \item \textbf{Personal Experience:} I have personally played all of these pieces and am very familiar with them. This firsthand knowledge allows for a deeper understanding and more accurate evaluation of the transcription results.
\end{itemize}



% \clearpage
% \FloatBarrier
\section{Comparison of Generated and Original Sheet Music}

The following sections provide a comparison of the generated sheet music with the original in terms of pitch. The generated sheet music is created by the AI model, while the original sheet music is the published version of the piece. Meaning of colors used in the generated sheet music:
\begin{itemize}
    \item \textbf{Red:} wrong note (in terms of pitch).
    \item \textbf{Green:} correct melody (in terms of pitch).
    \item \textbf{Blue:} correct accompaniament (in terms of pitch).
\end{itemize}

\subsection{F. Chopin - Etude op. 10 no. 5}

\subsubsection{Generated sheet music}
\hyperref[fig:generated_chopin]{Link to generated sheet music}

\subsubsection{Original sheet music}
\hyperref[fig:original_chopin]{Link to original sheet music}

\subsection{L. van Beethoven - Sonata op. 53 no. 21 "Waldstein", Allegro con brio}

\subsubsection{Generated sheet music}
\hyperref[fig:generated_waldstein]{Link to generated sheet music}

\subsubsection{Original sheet music}
\hyperref[fig:original_waldstein]{Link to original sheet music}

\subsection{L. van Beethoven - Sonata op. 13 no. 8 "Pathetique", Adagio cantabile}

\subsubsection{Generated sheet music}
\hyperref[fig:generated_pathetique]{Link to generated sheet music}

\subsubsection{Original sheet music}
\hyperref[fig:original_pathetique]{Link to original sheet music}


\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:generated_chopin}
    \includepdf[pages={1}]{../gen_notes/chopin.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:original_chopin}
    \includepdf[pages={22}]{../gen_notes/Chopin_Op.10.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:generated_waldstein}
    \includepdf[pages={1}]{../gen_notes/waldstein.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:original_waldstein}
    \includepdf[pages={3}]{../gen_notes/waldstein-1st-movement.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:generated_pathetique}
    \includepdf[pages={1}]{../gen_notes/Adagio-cantabile.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:original_pathetique}
    \includepdf[pages={8}]{../gen_notes/Pathetique.pdf}
\end{figure}




\FloatBarrier
\clearpage
\section{Results}

The comparison of the generated and original sheet music shows that the application is able to accurately transcribe grand piano recordings into sheet music. The generated sheet music closely resembles the original sheet music in terms of notes and proportion of notes length. However, there are a lot of differences in used notation, measure, tempo. The biggest problem is with grace notes, which are transcribed as regular notes, as well as measure. 

Interestingly, the transcribed notes are more precise than original. What I mean by that is that AI can capture the exact note length played by the pianist. That is not always good, because the pianist can play the note a little bit longer or shorter than it is written in the sheet music. That results in darkened transcription because the model transcribes perfectly the note length.

In terms of pitch, the AI model is able to accurately capture the notes played by the pianist. The generated sheet music reflects the original recording with a high degree of precision, capturing the nuances of the performance. The application is able to transcribe complex piano pieces with multiple voices and intricate rhythms, producing sheet music that is faithful to the original recording (but not necessarily to the original sheet music).

\section{Conclusion}
The application successfully transcribes grand piano recordings into sheet music with a high degree of accuracy. The generated sheet music closely resembles the original recording in terms of notes, rhythms, and dynamics. The AI model is able to capture the nuances of the performance, producing sheet music that accurately reflects the pianist's interpretation. The application provides a user-friendly interface for uploading audio files, viewing PDF previews, and downloading the resulting sheet music and MIDI files. The system architecture is designed to be modular and scalable, allowing for easy updates and future expansion. The application meets the performance, usability, compatibility, maintainability, and scalability requirements, providing a reliable and efficient solution for transcribing grand piano recordings to sheet music.

\FloatBarrier
\section{Possible Improvements}
\begin{itemize}
    \item \textbf{Improved AI Model:} Developing second AI model that will be responsible for postprocessing the output of the first model. This model will be responsible for correcting the tempo, measure, and notation of the generated sheet music. I believe that it is possible to acchieve, because there are some dependencies between notes that can be used to correct the output.
    \item \textbf{Enhanced User Interface:} Adding more features to the user interface, such as real-time transcription visualization, audio waveform display, and interactive sheet music editing.
    \item \textbf{Additional Output Formats:} Supporting more output formats, such as MusicXML, MIDI, and audio files, to provide users with more options for sharing
    \item \textbf{Performance Optimization:} Optimizing the transcription process to reduce the time required for generating sheet music and improving the accuracy of the results.
    \item \textbf{Creating web application:} Developing a web-based version of the application to make it accessible from any device with an internet connection.
\end{itemize}

\FloatBarrier
\section{References}
\begin{itemize}
    \item Qiuqiang Kong, Bochen Li, Xuchen Song, Yuan Wan, and Yuxuan Wang. "High-resolution Piano Transcription with Pedals by Regressing Onsets and Offsets Times." arXiv preprint arXiv:2010.01815 (2020). \href{https://arxiv.org/pdf/2010.01815.pdf}{[pdf]}
\end{itemize}

\end{document}
