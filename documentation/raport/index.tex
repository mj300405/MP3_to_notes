\documentclass{article}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{float} % For precise float placement
\usepackage{placeins} % For FloatBarrier
\usepackage{adjustbox} % For adjusting box sizes
\usepackage{pdfpages}
\usepackage{parskip}
\usepackage{indentfirst}

\setlength{\parindent}{2em} % Add this line to set paragraph indentation

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{2cm} % Adjust the vertical space as needed
    {\Huge \bfseries Application for Transcribing Grand Piano Recordings to Sheet Music in PDF\par}
    \vspace{8cm}
    {\Large \textbf{Subject:} Computer Engineering Project\par}
    \vspace{0.5cm}
    {\Large \textbf{Supervisor:} Prof. Mariagrazia Fugini\par}
    \vspace{0.5cm}
    {\Large \textbf{Author:} Micha≈Ç Jagoda\par}
    \vspace{0.5cm}
    {\Large \today\par}
    \vfill
\end{titlepage}

\clearpage % Start a new page before the ToC
\tableofcontents
\clearpage % Start a new page after the ToC

\section{Topic Analysis}

\subsection{Overview}
This project involves creating a desktop application designed to transcribe grand piano recordings into sheet music and export the results as a PDF. This involves the use of audio processing, music transcription, and PDF generation technologies, all performed locally without the need for an internet connection.

\subsection{Objectives}
\begin{itemize}
    \item To accurately transcribe piano recordings into readable sheet music.
    \item To provide a user-friendly interface for uploading audio files and exporting sheet music.
    \item To offer an offline and local application for accessibility and privacy reasons.
\end{itemize}

\subsection{Key Components}
\begin{itemize}
    \item \textbf{Audio Processing:} Capturing and processing the audio signals from the grand piano recordings using the \texttt{audio\_processor.py}.
    \item \textbf{AI Model:} Generating an initial transcription output from the uploaded MP3 file using the \texttt{transcription\_worker.py}.
    \item \textbf{Postprocessing Algorithm:} Creating a MIDI file from the AI model's output using the \texttt{Sheet\_music\_generation.py}.
    \item \textbf{PDF Generation:} Using the MuseScore API to generate a PDF from the generated MIDI file with \texttt{generate\_pdf.py}.
    \item \textbf{User Interface:} Allowing users to interact with the application, upload audio files, view PDF previews, listen to MIDI and MP3 files, and download the resulting sheet music and MIDI files via \texttt{window.py}.
\end{itemize}

\FloatBarrier % Ensures that all floats are processed before moving to the next section

\section{Technologies Used}
\begin{itemize}
    \item \textbf{Python:} The primary programming language used for developing the application.
    \item \textbf{Librosa:} A Python library for audio and music analysis, used for audio processing and feature extraction in \texttt{audio\_processor.py}.
    \item \textbf{Piano Transcription Inference:} A library for transcribing piano music, used in \texttt{transcription\_worker.py}.
    \item \textbf{Music21:} A toolkit for computer-aided musicology, used in \texttt{Sheet\_music\_generation.py} to create and manipulate music streams.
    \item \textbf{MuseScore:} A software for creating, playing, and printing sheet music, used in \texttt{generate\_pdf.py} to convert MIDI files to PDF.
    \item \textbf{PySide6:} A set of Python bindings for Qt libraries, used for creating the graphical user interface in \texttt{window.py}.
    \item \textbf{VLC:} A media player used for playing audio and MIDI files within the application.
    \item \textbf{Pdf2image:} A library for converting PDF files to images, used in the GUI to display PDF previews.
    \item \textbf{Tempfile:} A Python module used for creating temporary files, ensuring that the application handles file operations efficiently and securely.
    \item \textbf{WSL2 (Windows Subsystem for Linux):} Used to run some Python libraries that were not available on Windows. As WSL2 lacks support for audio and GUI components, server bridges were implemented to facilitate communication between the audio processing and GUI components running in different environments.
\end{itemize}

\FloatBarrier

\section{Functional Requirements}

\subsection{Core Functionalities}
\begin{itemize}
    \item \textbf{Audio File Upload:}
    \begin{itemize}
        \item Users can upload MP3 audio files.
    \end{itemize}
    \item \textbf{AI Model:}
    \begin{itemize}
        \item The system processes the uploaded audio using an AI model to generate an initial transcription.
    \end{itemize}
    \item \textbf{Postprocessing Algorithm:}
    \begin{itemize}
        \item The application converts the AI model's output into a MIDI file.
    \end{itemize}
    \item \textbf{PDF Generation:}
    \begin{itemize}
        \item The MuseScore API is used to convert the generated MIDI file into a PDF document.
    \end{itemize}
    \item \textbf{PDF Preview and Download:}
    \begin{itemize}
        \item Users can preview the PDF of the sheet music.
        \item Users can download the PDF and the MIDI file.
    \end{itemize}
    \item \textbf{Playback Feature:}
    \begin{itemize}
        \item Users can listen to the transcription by playing the MIDI file.
        \item Users can also listen to the original MP3 file.
    \end{itemize}
\end{itemize}

\FloatBarrier
\clearpage
\section{Non-Functional Requirements}

\subsection{Performance Requirements}
\begin{itemize}
    \item \textbf{Speed:} The transcription process should be completed within a reasonable time frame (under 15 minutes for a 5-minute recording).
    \item \textbf{Accuracy:} The transcription should accurately reflect the notes, rhythms, and dynamics of the original recording with a high degree of precision (over 90\% accuracy).
\end{itemize}

\subsection{Usability Requirements}
\begin{itemize}
    \item \textbf{User Interface:} The interface should be intuitive and easy to navigate, even for users with limited technical skills.
\end{itemize}

\subsection{Compatibility Requirements}
\begin{itemize}
    \item \textbf{File Format Support:} The application should support common audio file formats and produce PDFs that are compatible with standard PDF readers.
\end{itemize}

\subsection{Maintainability Requirements}
\begin{itemize}
    \item \textbf{Modularity:} The application code should be modular to facilitate easy updates and maintenance.
    \item \textbf{Documentation:} Comprehensive documentation should be provided for developers to understand the codebase and contribute to its development.
\end{itemize}

\subsection{Scalability Requirements}
\begin{itemize}
    \item \textbf{Future Expansion:} The architecture should allow for easy addition of new features and functionalities.
\end{itemize}

\FloatBarrier
\clearpage
\section{Use Case Diagram}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/use_case.png}
    \caption{Use Case Diagram}
    \label{fig:use_case}
\end{figure}

\FloatBarrier
\clearpage
\section{System Architecture Flow Chart}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/system_architecture.png}
    \caption{System Architecture Flow Chart}
    \label{fig:system_architecture}
\end{figure}

\FloatBarrier
\clearpage

\section{Class Diagram}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/class_diagram.png}
    \caption{Class Diagram}
    \label{fig:class_diagram}
\end{figure}

\FloatBarrier
\clearpage

\section{Sequence Diagrams}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/transcription_seq.png}
    \caption{Transcription process sequence diagram}
    \label{fig:transcription_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/audio_seq.png}
    \caption{Audio sequence diagram}
    \label{fig:audio_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/load_audio_seq.png}
    \caption{Load file sequence diagram}
    \label{fig:load_audio_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/save_midi_seq.png}
    \caption{Save MIDI sequence diagram}
    \label{fig:save_midi_sequence_diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/save_pdf_seq.png}
    \caption{Save PDF sequence diagram}
    \label{fig:save_pdf_sequence_diagram}
\end{figure}

\FloatBarrier
\clearpage

\section{AI Model Architecture}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../diagrams/ai_architecture.png}
    \caption{AI Model Architecture}
    \label{fig:ai_model_architecture}
\end{figure}

\section{Code implementation}

For the implementation of the application I encourage you to visit the GitHub repository: \href{https://github.com/mj300405/MP3_to_notes}{link to the repository}.


\clearpage
\FloatBarrier
\section{Comparison of Generated and Original Sheet Music}

\subsection{F. Chopin - Etude op. 10 no. 5}

\subsubsection{Generated sheet music}
\hyperref[fig:generated_chopin]{Link to generated sheet music}

\subsubsection{Original sheet music}
\hyperref[fig:original_chopin]{Link to original sheet music}

\subsection{L. van Beethoven - Sonata op. 53 no. 21 "Waldstein", Allegro con brio}

\subsubsection{Generated sheet music}
\hyperref[fig:generated_waldstein]{Link to generated sheet music}

\subsubsection{Original sheet music}
\hyperref[fig:original_waldstein]{Link to original sheet music}

\subsection{L. van Beethoven - Sonata op. 13 no. 8 "Pathetique", Adagio cantabile}

\subsubsection{Generated sheet music}
\hyperref[fig:generated_pathetique]{Link to generated sheet music}

\subsubsection{Original sheet music}
\hyperref[fig:original_pathetique]{Link to original sheet music}


\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:generated_chopin}
    \includepdf[pages={1}]{../gen_notes/chopin.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:original_chopin}
    \includepdf[pages={22}]{../gen_notes/Chopin_Op.10.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:generated_waldstein}
    \includepdf[pages={1}]{../gen_notes/waldstein.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:original_waldstein}
    \includepdf[pages={3}]{../gen_notes/waldstein-1st-movement.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:generated_pathetique}
    \includepdf[pages={1}]{../gen_notes/Adagio-cantabile.pdf}
\end{figure}

\clearpage
\begin{figure}[htbp]
    \centering
    \phantomsection
    \label{fig:original_pathetique}
    \includepdf[pages={8}]{../gen_notes/Pathetique.pdf}
\end{figure}




\FloatBarrier
\clearpage
\section{Results}

The comparison of the generated and original sheet music shows that the application is able to accurately transcribe grand piano recordings into sheet music. The generated sheet music closely resembles the original sheet music in terms of notes and proportion of notes length. However, there are a lot of differences in used notation, measure, tempo. The biggest problem is with grace notes, which are transcribed as regular notes, as well as measure. 

Interestingly, the transcribed notes are more precise than original. What I mean by that is that AI can capture the exact note length played by the pianist. That is not always good, because the pianist can play the note a little bit longer or shorter than it is written in the sheet music. That results in darkened transcription because the model transcribes perfectly the note length.

In terms of pitch, the AI model is able to accurately capture the notes played by the pianist. The generated sheet music reflects the original recording with a high degree of precision, capturing the nuances of the performance. The application is able to transcribe complex piano pieces with multiple voices and intricate rhythms, producing sheet music that is faithful to the original recording (but not necessarily to the original sheet music).

\section{Conclusion}
The application successfully transcribes grand piano recordings into sheet music with a high degree of accuracy. The generated sheet music closely resembles the original recording in terms of notes, rhythms, and dynamics. The AI model is able to capture the nuances of the performance, producing sheet music that accurately reflects the pianist's interpretation. The application provides a user-friendly interface for uploading audio files, viewing PDF previews, and downloading the resulting sheet music and MIDI files. The system architecture is designed to be modular and scalable, allowing for easy updates and future expansion. The application meets the performance, usability, compatibility, maintainability, and scalability requirements, providing a reliable and efficient solution for transcribing grand piano recordings to sheet music.

\FloatBarrier
\section{Possible Improvements}
\begin{itemize}
    \item \textbf{Improved AI Model:} Developing second AI model that will be responsible for postprocessing the output of the first model. This model will be responsible for correcting the tempo, measure, and notation of the generated sheet music. I believe that it is possible to acchieve, because there are some dependencies between notes that can be used to correct the output.
    \item \textbf{Enhanced User Interface:} Adding more features to the user interface, such as real-time transcription visualization, audio waveform display, and interactive sheet music editing.
    \item \textbf{Additional Output Formats:} Supporting more output formats, such as MusicXML, MIDI, and audio files, to provide users with more options for sharing
    \item \textbf{Performance Optimization:} Optimizing the transcription process to reduce the time required for generating sheet music and improving the accuracy of the results.
    \item \textbf{Creating web application:} Developing a web-based version of the application to make it accessible from any device with an internet connection.
\end{itemize}

\FloatBarrier
\section{References}
\begin{itemize}
    \item Qiuqiang Kong, Bochen Li, Xuchen Song, Yuan Wan, and Yuxuan Wang. "High-resolution Piano Transcription with Pedals by Regressing Onsets and Offsets Times." arXiv preprint arXiv:2010.01815 (2020). \href{https://arxiv.org/pdf/2010.01815.pdf}{[pdf]}
\end{itemize}

\end{document}
